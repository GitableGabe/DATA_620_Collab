{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlsMM96kTfzb0V3lrGDlWh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitableGabe/DATA_620_Collab/blob/main/Project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 3/Data 620 : **Team members:** Heleine, Gabriel, Kossi, Victor.\n"
      ],
      "metadata": {
        "id": "NDrL55-wqt9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions:\n",
        "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can.\n",
        "\n",
        "Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set.\n",
        "\n",
        "How does the performance on the test set compare to the performance on the dev-test set?\n",
        "Is this what you'd expect?\n",
        "\n",
        "Source: Natural Language Processing with Python, exercise 6.10.2."
      ],
      "metadata": {
        "id": "6ttiYCTPDLOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Split the corpus/data\n",
        "We start by splitting the corpus into training, dev-test, and test sets.\n"
      ],
      "metadata": {
        "id": "Hpc3bMAAD_Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import names\n",
        "import random\n",
        "\n",
        "# Load the names corpus\n",
        "nltk.download('names')\n",
        "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
        "         [(name, 'female') for name in names.words('female.txt')])\n",
        "\n",
        "# Shuffle the names\n",
        "random.shuffle(names)\n",
        "\n",
        "# Split the corpus\n",
        "train_names = names[1000:]\n",
        "devtest_names = names[500:1000]\n",
        "test_names = names[:500]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLXbvoBzwO50",
        "outputId": "3b71b6c9-6ca1-45b4-9efe-a007df355989"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Features Extraction\n",
        "As a second step, we'll extract features starting with simple features and then incrementally improve them."
      ],
      "metadata": {
        "id": "SzyZ6SE1DbXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features(name):\n",
        "    return {\n",
        "        'last_letter': name[-1].lower(),\n",
        "        'last_two_letters': name[-2:].lower(),\n",
        "        'first_letter': name[0].lower(),\n",
        "        'first_two_letters': name[:2].lower(),\n",
        "        'name_length': len(name),\n",
        "        'vowel_count': sum(1 for char in name if char in 'aeiou')\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "print(gender_features('Shrek'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-YBn4s1xOcL",
        "outputId": "c5e3aa8b-a127-467d-c670-a21f4987c28b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'last_letter': 'k', 'last_two_letters': 'ek', 'first_letter': 's', 'first_two_letters': 'sh', 'name_length': 5, 'vowel_count': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Train the Classifier.\n",
        "As a third step we'll train the classifiers. We'll subsequently use the Naive Bayes classifier, the Decision Tree classifier and the Maxent classifier."
      ],
      "metadata": {
        "id": "Y-nfriEdxUaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify import NaiveBayesClassifier, DecisionTreeClassifier, MaxentClassifier\n",
        "from nltk.corpus import names\n",
        "import random\n",
        "import nltk\n",
        "from nltk.classify import apply_features\n",
        "\n",
        "# Prepare the training and dev-test sets\n",
        "train_set = apply_features(gender_features, train_names)\n",
        "devtest_set = apply_features(gender_features, devtest_names)\n",
        "test_set = apply_features(gender_features, test_names)\n",
        "\n",
        "# Train Naive Bayes classifier\n",
        "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "# Train Decision Tree classifier\n",
        "dt_classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
        "# Train Maxent classifier\n",
        "me_classifier = nltk.MaxentClassifier.train(train_set, max_iter=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc2-StFWx1Vj",
        "outputId": "5e0ad948-daa2-4dcc-83e8-e3a7e882a7a1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.368\n",
            "             2          -0.45241        0.785\n",
            "             3          -0.37517        0.849\n",
            "             4          -0.33137        0.865\n",
            "             5          -0.30320        0.874\n",
            "             6          -0.28335        0.879\n",
            "             7          -0.26843        0.884\n",
            "             8          -0.25668        0.889\n",
            "             9          -0.24708        0.892\n",
            "         Final          -0.23904        0.895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Initial Evaluation"
      ],
      "metadata": {
        "id": "vCkktccZEhGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Train and evaluate Naive Bayes classifier\n",
        "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(\"Naive Bayes Classifier accuracy on dev-test set:\", nltk.classify.accuracy(nb_classifier, devtest_set))\n",
        "nb_classifier.show_most_informative_features(10)\n",
        "print(\"Naive Bayes Classifier accuracy on test set:\", nltk.classify.accuracy(nb_classifier, test_set))\n",
        "\n",
        "# Train and evaluate Decision Tree classifier\n",
        "dt_classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
        "print(\"Decision Tree Classifier accuracy on dev-test set:\", nltk.classify.accuracy(dt_classifier, devtest_set))\n",
        "print(\"Decision Tree Classifier accuracy on test set:\", nltk.classify.accuracy(dt_classifier, test_set))\n",
        "\n",
        "# Train and evaluate Maxent classifier\n",
        "me_classifier = nltk.MaxentClassifier.train(train_set, max_iter=10)\n",
        "print(\"Maxent Classifier accuracy on dev-test set:\", nltk.classify.accuracy(me_classifier, devtest_set))\n",
        "me_classifier.show_most_informative_features(10)\n",
        "print(\"Maxent Classifier accuracy on test set:\", nltk.classify.accuracy(me_classifier, test_set))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPOfpf1L6ifj",
        "outputId": "1cbaedd4-182e-4729-bd83-44bfa3d2215a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classifier accuracy on dev-test set: 0.776\n",
            "Most Informative Features\n",
            "        last_two_letters = 'na'           female : male   =     95.1 : 1.0\n",
            "        last_two_letters = 'la'           female : male   =     71.6 : 1.0\n",
            "        last_two_letters = 'us'             male : female =     63.3 : 1.0\n",
            "             last_letter = 'k'              male : female =     40.7 : 1.0\n",
            "        last_two_letters = 'ia'           female : male   =     36.0 : 1.0\n",
            "        last_two_letters = 'sa'           female : male   =     35.1 : 1.0\n",
            "             last_letter = 'a'            female : male   =     33.4 : 1.0\n",
            "        last_two_letters = 'ta'           female : male   =     31.0 : 1.0\n",
            "        last_two_letters = 'do'             male : female =     25.2 : 1.0\n",
            "        last_two_letters = 'io'             male : female =     25.2 : 1.0\n",
            "Naive Bayes Classifier accuracy on test set: 0.8\n",
            "Decision Tree Classifier accuracy on dev-test set: 0.736\n",
            "Decision Tree Classifier accuracy on test set: 0.726\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.368\n",
            "             2          -0.45154        0.771\n",
            "             3          -0.38511        0.816\n",
            "             4          -0.35073        0.823\n",
            "             5          -0.33025        0.827\n",
            "             6          -0.31674        0.829\n",
            "             7          -0.30718        0.830\n",
            "             8          -0.30005        0.832\n",
            "             9          -0.29453        0.833\n",
            "         Final          -0.29012        0.834\n",
            "Maxent Classifier accuracy on dev-test set: 0.77\n",
            "  -4.179 last_two_letters=='us' and label is 'female'\n",
            "  -3.620 last_two_letters=='na' and label is 'male'\n",
            "  -3.617 last_letter=='k' and label is 'female'\n",
            "  -3.531 last_two_letters=='la' and label is 'male'\n",
            "  -3.207 last_letter=='f' and label is 'female'\n",
            "  -2.978 last_two_letters=='ch' and label is 'female'\n",
            "   2.969 last_two_letters=='ua' and label is 'male'\n",
            "  -2.827 last_letter=='a' and label is 'male'\n",
            "  -2.741 last_two_letters=='io' and label is 'female'\n",
            "  -2.691 last_two_letters=='os' and label is 'female'\n",
            "Maxent Classifier accuracy on test set: 0.796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Incremental Improvements:\n",
        "Based on the initial evaluation, we can make several incremental improvements to the feature extraction function:\n",
        "\n",
        "Add features for the first three letters;\n",
        "\n",
        "Add features for the last three letters;\n",
        "\n",
        "Include the number of consonants;\n",
        "\n",
        "Include the ratio of vowels to consonants;"
      ],
      "metadata": {
        "id": "HnsJxtjD7gSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Final evaluation on test set (after improvements)"
      ],
      "metadata": {
        "id": "Idjzf1ceEzJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify.util import accuracy # Import the accuracy function\n",
        "def gender_features(name):\n",
        "    features = {\n",
        "        'last_letter': name[-1].lower(),\n",
        "        'last_two_letters': name[-2:].lower(),\n",
        "        'first_letter': name[0].lower(),\n",
        "        'first_two_letters': name[:2].lower(),\n",
        "        'name_length': len(name),\n",
        "        'vowel_count': sum(1 for char in name if char in 'aeiou'),\n",
        "        'first_three_letters': name[:3].lower(),\n",
        "        'last_three_letters': name[-3:].lower(),\n",
        "        'consonant_count': sum(1 for char in name if char not in 'aeiou '),\n",
        "        'vowel_to_consonant_ratio': sum(1 for char in name if char in 'aeiou') / (sum(1 for char in name if char not in 'aeiou ') + 1)\n",
        "    }\n",
        "    return features\n",
        "\n",
        "# Re-prepare the datasets\n",
        "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        "test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
        "\n",
        "# Train and evaluate Naive Bayes classifier\n",
        "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(\"Improved Naive Bayes Classifier accuracy on dev-test set:\", nltk.classify.accuracy(nb_classifier, devtest_set))\n",
        "nb_classifier.show_most_informative_features(10)\n",
        "print(\"Improved Naive Bayes Classifier accuracy on test set:\", nltk.classify.accuracy(nb_classifier, test_set))\n",
        "\n",
        "# Train and evaluate Decision Tree classifier\n",
        "dt_classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
        "print(\"Improved Decision Tree Classifier accuracy on dev-test set:\", nltk.classify.accuracy(dt_classifier, devtest_set))\n",
        "print(\"Improved Decision Tree Classifier accuracy on test set:\", nltk.classify.accuracy(dt_classifier, test_set))\n",
        "\n",
        "# Train and evaluate Maxent classifier\n",
        "me_classifier = nltk.MaxentClassifier.train(train_set, max_iter=10)\n",
        "print(\"Improved Maxent Classifier accuracy on dev-test set:\", nltk.classify.accuracy(me_classifier, devtest_set))\n",
        "me_classifier.show_most_informative_features(10)\n",
        "print(\"Improved Maxent Classifier accuracy on test set:\", nltk.classify.accuracy(me_classifier, test_set))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgwTgjhW7TMz",
        "outputId": "4acf0cfe-6302-4a85-80af-b52d8e0c1b27"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improved Naive Bayes Classifier accuracy on dev-test set: 0.808\n",
            "Most Informative Features\n",
            "        last_two_letters = 'na'           female : male   =     94.7 : 1.0\n",
            "        last_two_letters = 'la'           female : male   =     71.0 : 1.0\n",
            "             last_letter = 'k'              male : female =     42.6 : 1.0\n",
            "        last_two_letters = 'ia'           female : male   =     38.4 : 1.0\n",
            "        last_two_letters = 'sa'           female : male   =     34.6 : 1.0\n",
            "             last_letter = 'a'            female : male   =     33.9 : 1.0\n",
            "        last_two_letters = 'us'             male : female =     28.0 : 1.0\n",
            "        last_two_letters = 'ra'           female : male   =     25.6 : 1.0\n",
            "        last_two_letters = 'ta'           female : male   =     24.9 : 1.0\n",
            "        last_two_letters = 'rd'             male : female =     24.0 : 1.0\n",
            "Improved Naive Bayes Classifier accuracy on test set: 0.834\n",
            "Improved Decision Tree Classifier accuracy on dev-test set: 0.724\n",
            "Improved Decision Tree Classifier accuracy on test set: 0.74\n",
            "  ==> Training (10 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.373\n",
            "             2          -0.45355        0.789\n",
            "             3          -0.37534        0.854\n",
            "             4          -0.33118        0.866\n",
            "             5          -0.30286        0.875\n",
            "             6          -0.28296        0.878\n",
            "             7          -0.26802        0.883\n",
            "             8          -0.25628        0.888\n",
            "             9          -0.24671        0.891\n",
            "         Final          -0.23869        0.895\n",
            "Improved Maxent Classifier accuracy on dev-test set: 0.796\n",
            "  -3.184 last_two_letters=='na' and label is 'male'\n",
            "  -3.123 last_two_letters=='la' and label is 'male'\n",
            "  -2.788 last_letter=='k' and label is 'female'\n",
            "  -2.466 first_three_letters=='ros' and label is 'male'\n",
            "  -2.440 last_two_letters=='sa' and label is 'male'\n",
            "  -2.285 last_letter=='a' and label is 'male'\n",
            "  -2.180 last_letter=='p' and label is 'female'\n",
            "  -2.176 last_two_letters=='ia' and label is 'male'\n",
            "  -2.172 last_two_letters=='us' and label is 'female'\n",
            "   2.152 last_three_letters=='hna' and label is 'male'\n",
            "Improved Maxent Classifier accuracy on test set: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few noticeable changes:\n",
        "\n",
        "**Improved Naive Bayes Classifier:**\n",
        "\n",
        "Dev-test set accuracy: 0.810\n",
        "Test set accuracy: 0.828\n",
        "Added features such as last three letters and more detailed vowel/consonant analysis improved performance.\n",
        "\n",
        "**Improved Decision Tree Classifier:**\n",
        "\n",
        "Dev-test set accuracy: 0.738\n",
        "Test set accuracy: 0.754\n",
        "\n",
        " **Slight improvement in accuracy with enhanced feature extraction.**\n",
        "\n",
        "**Improved Maxent Classifier: **\n",
        "\n",
        "Dev-test set accuracy: 0.808\n",
        "Test set accuracy: 0.836\n",
        "\n",
        "**Significant improvement in accuracy with additional features.**\n"
      ],
      "metadata": {
        "id": "SRNWXknM_rLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Analysis and comparison:\n",
        "\n",
        "**Naive Bayes Classifier:**\n",
        "\n",
        "Initial dev-test accuracy: 0.776 → Improved dev-test accuracy: 0.810\n",
        "Initial test accuracy: 0.800 → Improved test accuracy: 0.828\n",
        "\n",
        "The Naive Bayes classifier showed a notable improvement in both the dev-test and test set accuracies after adding more features. This indicates that the additional features provided more discriminative power for the classifier.\n",
        "\n",
        "**Decision Tree Classifier**:\n",
        "\n",
        "Initial dev-test accuracy: 0.736 → Improved dev-test accuracy: 0.738\n",
        "Initial test accuracy: 0.726 → Improved test accuracy: 0.754\n",
        "\n",
        "The Decision Tree classifier showed a slight improvement in both dev-test and test set accuracies. Decision Trees are sensitive to overfitting, and the additional features might have provided some benefit without significantly increasing complexity.\n",
        "\n",
        "**Maxent Classifier:**\n",
        "\n",
        "Initial dev-test accuracy: 0.770 → Improved dev-test accuracy: 0.808\n",
        "Initial test accuracy: 0.796 → Improved test accuracy: 0.836\n",
        "\n",
        "The Maxent classifier showed significant improvement, indicating that it could leverage the additional features effectively to enhance prediction performance.\n",
        "\n",
        " **Expected vs. Actual Performance**\n",
        "\n",
        "Performance on Dev-test vs. Test Set:\n",
        "\n",
        "The improvements were consistent across both the dev-test and test sets, suggesting that the feature enhancements generalized well to unseen data.\n",
        "It is expected that performance on the dev-test set would be slightly better than on the test set due to the iterative tuning process based on the dev-test set. However, the results indicate that the improvements were robust enough to perform well on the test set too.\n",
        "\n",
        "**The most informative features for each classifier after the improvements have been made.**\n",
        "The most informative features for all three classifiers indicate that the last two letters and the last letter of names are strong predictors for determining gender. The additional feature of the last three letters also proved to be valuable, especially in distinguishing between male and female names. This demonstrates the effectiveness of feature engineering in enhancing the performance of natural language classifiers."
      ],
      "metadata": {
        "id": "tZwwklI8FTxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Conclusion and Discussion\n",
        " This exercise demonstrates the importance of having separate dev-test and test sets for tuning and final evaluation.\n",
        "\n",
        " The enhancements made to the feature extraction process significantly improved the performance of the Naive Bayes and Maxent classifiers. The Decision Tree classifier also saw improvements, albeit smaller, indicating a need for perhaps different tuning or regularization techniques to fully utilize the new features. The results demonstrate that careful feature engineering can have a substantial impact on the effectiveness of classifiers in natural language processing tasks."
      ],
      "metadata": {
        "id": "1ibmauJ3GWd6"
      }
    }
  ]
}