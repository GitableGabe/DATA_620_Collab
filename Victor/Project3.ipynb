{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343f7a6b-1a91-4656-9e21-bc0f08a45c55",
   "metadata": {},
   "source": [
    "Project 3\n",
    "DATA 620\n",
    "Heliene, Gabriel, Kossi, Victor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7712cc-2864-49bf-8b8c-d93b532adf46",
   "metadata": {},
   "source": [
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. \r\n",
    "\r\n",
    "Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set.\r\n",
    "\r\n",
    "How does the performance on the test set compare to the performance on the dev-test set?\r\n",
    "Is this what you'd expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f10e16-d849-4e61-acda-d4aecf964ad7",
   "metadata": {},
   "source": [
    "We decided to use the Naive Bayes Classifier for our project, we will use pandas library for analysis, intertools and string libraries as tools to build the name gender classifier. we will subset the corpus into three subsets, and the remaining words for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9259d7cc-cf80-4a02-9dee-cd276ac75655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\vitug\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import required libraries and tools for this project.\n",
    "#Download 'names'.\n",
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from string import ascii_lowercase\n",
    "nltk.download('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9c11390b-f621-4ddd-83db-5f89e96e049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get male and female names from corpus.\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n",
    "#shuffle names randomly.\n",
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cab97c82-a47a-41a0-b611-8299c374eb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7944\n"
     ]
    }
   ],
   "source": [
    "#Setting the three sets of names\n",
    "test, dev_test, training = names[:500], names[500:1000], names[1000:]\n",
    "#Print lenght of \"names\"\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85199b43-b9f9-4069-a5e9-34af51b00a00",
   "metadata": {},
   "source": [
    "Create first name gender model classifier using first letter, last letter and suffix as main features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9aa5892-28e3-424f-9b44-320d0139890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_model1(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc4fa7-7e1a-4813-a25d-3f7e846be271",
   "metadata": {},
   "source": [
    "Train the data of first model and check accuracy using dev test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "408a8c6b-c3ab-4eb5-be60-502986625db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using model 1 is: 0.774\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_model1(n), g) for (n,g) in training]\n",
    "dev_test_set = [(gender_model1(n), g) for (n,g) in dev_test]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "#Use Dev_test to check accuracy and print results\n",
    "acc_dev_test_1 = nltk.classify.accuracy(classifier, dev_test_set)\n",
    "print(\"Accuracy using model 1 is: \" + str(acc_dev_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "00ca59fe-e482-4c20-8b39-d0554eb3c2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test using model 1 is: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Performance test of model 1\n",
    "test_set = [(gender_model1(n), g) for (n,g) in test]\n",
    "test_set_1 = nltk.classify.accuracy(classifier, test_set)\n",
    "print(\"Accuracy for test using model 1 is: \" + str(test_set_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c19063a-9f58-41ee-9ebb-707cfdade6f2",
   "metadata": {},
   "source": [
    "Create second name classifier model using first letter, last letter and two suffixes as main features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16f4871f-c75f-4f6e-965c-e5f1bb3c7283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_model2(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    features[\"suffix3\"] = name[-3:].lower()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4598d3-139f-45b2-8551-484687b8a728",
   "metadata": {},
   "source": [
    "Train Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e06f2947-568e-4a67-b67b-16855a1658fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using model 2 is: 0.782\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_model2(n), g) for (n,g) in training]\n",
    "dev_test_set = [(gender_model2(n), g) for (n,g) in dev_test]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "#Use Dev_test to check accuracy and print results\n",
    "acc_dev_test_2 = nltk.classify.accuracy(classifier, dev_test_set)\n",
    "print(\"Accuracy using model 2 is: \" + str(acc_dev_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c6d9b686-f588-4ae1-823b-957fb23f2a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test using model 2 is: 0.818\n"
     ]
    }
   ],
   "source": [
    "# Performance test Model 2\n",
    "test_set = [(gender_model2(n), g) for (n,g) in test]\n",
    "test_set_2 = nltk.classify.accuracy(classifier, test_set)\n",
    "print(\"Accuracy for test using model 2 is: \" + str(test_set_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c295b-445e-4d9e-930c-f17b8d8a4335",
   "metadata": {},
   "source": [
    "Create third name classifier model using first letter, last letter and three suffixes as main features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "226aee1e-fdee-4841-86e8-b08c67ed4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_model3(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    features[\"suffix3\"] = name[-3:].lower()\n",
    "    features[\"prefix3\"] = name[:3].lower()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70462799-0aff-460d-90d3-2f8d6bcc0bb2",
   "metadata": {},
   "source": [
    "Train third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "88b69829-71f8-47b3-a0f9-33f4b499a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using model 3 is: 0.808\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_model3(n), g) for (n,g) in training]\n",
    "dev_test_set = [(gender_model3(n), g) for (n,g) in dev_test]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "#Use Dev_test to check accuracy and print results\n",
    "acc_dev_test_3 = nltk.classify.accuracy(classifier, dev_test_set)\n",
    "print(\"Accuracy using model 3 is: \" + str(acc_dev_test_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a2f0e16-4230-4212-bb3a-2ac34e941d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test using model 3 is: 0.832\n"
     ]
    }
   ],
   "source": [
    "# Performance test model 3\n",
    "test_set = [(gender_model3(n), g) for (n,g) in test]\n",
    "test_set_3 = nltk.classify.accuracy(classifier, test_set)\n",
    "print(\"Accuracy for test using model 3 is: \" + str(test_set_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae70807-e144-4c43-ae67-c7afcbfb4df2",
   "metadata": {},
   "source": [
    "Create fourth name classifier model using first, first two letters, last, last two letter as main features, \n",
    "as well as to convert all text to lowercase as keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a968f1c4-a29d-4913-a15b-977629178e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_model4(name):\n",
    "    \n",
    "    features = {}\n",
    "    keywords = [''.join(i) for i in itertools.product(ascii_lowercase, repeat = 2)]\n",
    "    \n",
    "    #apply .lower() method to convert all text to lowercase\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"first_2letter\"] = name[0:1].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"last_2letter\"] = name[-2:-1].lower()\n",
    "    \n",
    "    for letter in ascii_lowercase:\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "\n",
    "        for keyword in keywords:\n",
    "            features[\"combo2({})\".format(keyword)] = (keyword in name.lower())\n",
    "            \n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a99b827-6ea2-42d9-8757-9ae8855d65db",
   "metadata": {},
   "source": [
    "Train Fourth Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a73dc82c-48e6-41c4-a784-e638c35ee254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using model 4 is: 0.792\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_model4(n), g) for (n,g) in training]\n",
    "dev_test_set = [(gender_model4(n), g) for (n,g) in dev_test]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "#Use Dev_test to check accuracy and print results\n",
    "acc_dev_test_4 = nltk.classify.accuracy(classifier, dev_test_set)\n",
    "print(\"Accuracy using model 4 is: \" + str(acc_dev_test_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c8f0c8dc-6e4a-48f6-855a-0af48285514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test using model 4 is: 0.812\n"
     ]
    }
   ],
   "source": [
    "# Performance test model 4\n",
    "test_set = [(gender_model4(n), g) for (n,g) in test]\n",
    "test_set_4 = nltk.classify.accuracy(classifier, test_set)\n",
    "print(\"Accuracy for test using model 4 is: \" + str(test_set_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a6c1cf-766a-4575-9d65-5ecf390d48b9",
   "metadata": {},
   "source": [
    "Simulation Model of Name Gender Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2666c02a-ade2-48c7-acc3-bbfb0da139c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AccuracySimulation(numIterations, callBackFunction):\n",
    "    acc_df = {\n",
    "        \"classifier\": [],\n",
    "        \"test_set_accuracy\": [],\n",
    "        \"dev_test_set_accuracy\": [],\n",
    "        \"train_set_accuracy\": []\n",
    "    }\n",
    "    for i in range(numIterations):\n",
    "        random.shuffle(names)\n",
    "        acc_train_names = names[1000:]\n",
    "        acc_dev_test_names = names[500:1000]\n",
    "        acc_test_names = names[:500]\n",
    "        acc_train_set = [(callBackFunction(n), g) for (n,g) in acc_train_names]\n",
    "        acc_dev_test_set = [(callBackFunction(n), g) for (n,g) in acc_dev_test_names]\n",
    "        acc_test_set = [(callBackFunction(n), g) for (n,g) in acc_test_names]\n",
    "        acc_classifier = nltk.NaiveBayesClassifier.train(acc_train_set)\n",
    "        acc_df[\"classifier\"].append(acc_classifier) \n",
    "        acc_df[\"test_set_accuracy\"].append(nltk.classify.accuracy(acc_classifier, acc_test_set))\n",
    "        acc_df[\"dev_test_set_accuracy\"].append(nltk.classify.accuracy(acc_classifier, acc_dev_test_set))\n",
    "        acc_df[\"train_set_accuracy\"].append(nltk.classify.accuracy(acc_classifier, acc_train_set))\n",
    "       \n",
    "    acc_df = pd.DataFrame.from_dict(acc_df)\n",
    "    return(acc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b97d58-5f8d-4540-ac99-a52cf8e2111f",
   "metadata": {},
   "source": [
    "Calculation of some Statistical data between values using .describe function in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5355de8e-46df-43fc-ac14-be0d66d90f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = AccuracySimulation(10, gender_model1)\n",
    "df_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5157f-924d-49f9-bc5e-ab23dad22ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = AccuracySimulation(10, gender_model2)\n",
    "df_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b903ec9-6445-4256-919e-90a659837c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = AccuracySimulation(10, gender_model3)\n",
    "df_3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a616433c-602a-43e1-9596-4e24b9a992ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_set_accuracy</th>\n",
       "      <th>dev_test_set_accuracy</th>\n",
       "      <th>train_set_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.804400</td>\n",
       "      <td>0.800200</td>\n",
       "      <td>0.815049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.019772</td>\n",
       "      <td>0.012665</td>\n",
       "      <td>0.001551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.768000</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.812788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.793000</td>\n",
       "      <td>0.790500</td>\n",
       "      <td>0.814048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.799000</td>\n",
       "      <td>0.815452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.807500</td>\n",
       "      <td>0.815920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.817540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_set_accuracy  dev_test_set_accuracy  train_set_accuracy\n",
       "count          10.000000              10.000000           10.000000\n",
       "mean            0.804400               0.800200            0.815049\n",
       "std             0.019772               0.012665            0.001551\n",
       "min             0.768000               0.784000            0.812788\n",
       "25%             0.793000               0.790500            0.814048\n",
       "50%             0.806000               0.799000            0.815452\n",
       "75%             0.814000               0.807500            0.815920\n",
       "max             0.834000               0.820000            0.817540"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4 = AccuracySimulation(10, gender_model4)\n",
    "df_4.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
